{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_KK2usinYme"
   },
   "source": [
    "# URLs para obtenção dos datasets (Obtido dia 07/06/2021)\n",
    "- ### Explicação dos datasets: https://repositoriodatasharingfapesp.uspdigital.usp.br/\n",
    "- ### Dataset do hospital Albert Einstein: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/98 - (2020-06-30)\n",
    "- ### Dataset do hospital Sirio Libanes: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/97 (2020-06-30)\n",
    "- ### Dataset do hospital Beneficencia Portuguesa: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/101 (2021-04-28)\n",
    "- ### Dataset do grupo Fleury: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/99 - (2020-06-30)\n",
    "- ### Dataset do hospital das clinicas da faculdade de medicina da Universidade de São Paulo: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/100 - (2021-02-17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LHakcR8arKVZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "current_path = os.path.abspath(os.getcwd())\n",
    "sys.path.append(f\"{current_path}/../libs\")\n",
    "\n",
    "from dataframe import read_dataset\n",
    "from report import dataset_info_report, model_report, feature_selection_report\n",
    "from preprocess import remove_sparse_rows, remove_sparse_columns, under_sampling, one_hot_encoded\n",
    "from feature_selection import get_k_best_features\n",
    "from cross_validation import get_folds\n",
    "from config import load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reading Configs and Defining Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"../config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_feature_selection = {}\n",
    "report_models = {}\n",
    "report_dataset_info = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Reading Normalized Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for dataset in config.DATASETS:\n",
    "    df = read_dataset(dataset).drop(\"ID_PACIENTE\",axis=1)\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df,dataset in zip(df_list,config.DATASETS):\n",
    "    if \"raw dataset\" not in report_dataset_info:\n",
    "        report_dataset_info[\"raw dataset\"]={}\n",
    "    report_dataset_info[\"raw dataset\"][dataset]=dataset_info_report(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df_list = []\n",
    "report_dataset_info[\"preprocessed_dataset\"]={}\n",
    "for df,dataset in zip(df_list,config.DATASETS):\n",
    "    preprocessed_df = remove_sparse_columns(df)\n",
    "    preprocessed_df = remove_sparse_rows(preprocessed_df)\n",
    "    report_dataset_info[\"preprocessed_dataset\"][dataset]=dataset_info_report(preprocessed_df)\n",
    "    one_hot_encoded_df = one_hot_encoded(preprocessed_df)\n",
    "    preprocessed_df_list.append(one_hot_encoded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Applying Feature Selection and Machine Learning Models With Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"Decision Tree\" : tree.DecisionTreeClassifier(),\n",
    "    \"Random Forest\" : RandomForestClassifier(random_state=42),\n",
    "    \"KNN\" : KNeighborsClassifier(),\n",
    "    \"Logistic Regression\" : LogisticRegression(max_iter=1000),\n",
    "    \"SVM\" : SVC(probability=True, class_weight='balanced')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ricardo/Desktop/tcc/tcc-02/.venv/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [22] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/ricardo/Desktop/tcc/tcc-02/.venv/lib/python3.8/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "\n",
    "report_feature_selection['select-k-best']={}\n",
    "\n",
    "for df,dataset in zip(preprocessed_df_list,config.DATASETS):\n",
    "    report_feature_selection['select-k-best'][dataset]={}\n",
    "    report_models[dataset]={} \n",
    "    folds = get_folds(df,config.N_FOLDS)\n",
    "    for index,fold in enumerate(folds):\n",
    "\n",
    "        train_df,test_df=fold\n",
    "        train_df = under_sampling(train_df,False)\n",
    "        test_df = under_sampling(test_df,False)\n",
    "\n",
    "        X_train = train_df.drop([\"LABEL\"],axis=1)\n",
    "        y_train = train_df[\"LABEL\"]\n",
    "        X_test = test_df.drop([\"LABEL\"],axis=1)\n",
    "        y_test = test_df[\"LABEL\"]\n",
    "        \n",
    "        X_k_best = get_k_best_features(X_train,y_train.values.ravel(), config.N_FEATURES)\n",
    "        report_feature_selection['select-k-best'][dataset][f\"fold {index}\"]=feature_selection_report(X_k_best.columns.to_list())\n",
    "\n",
    "        models = {key: MODELS[key] for key in config.MODELS}\n",
    "        for model in models.items():\n",
    "            model[1].fit(X_train, y_train.values.ravel())\n",
    "            y_predicted=model[1].predict(X_test)\n",
    "            if model[0] not in report_models[dataset]:\n",
    "                report_models[dataset][model[0]]={}\n",
    "            report_models[dataset][model[0]][f\"fold {index}\"]=model_report(y_test,y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Save Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = config.REPORT_PATH\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "with open(f\"{path}models.json\", 'w') as f:\n",
    "    json.dump(report_models, f)\n",
    "\n",
    "with open(f\"{path}features.json\", 'w') as f:\n",
    "    json.dump(report_feature_selection, f)\n",
    "\n",
    "with open(f\"{path}info.json\", 'w') as f:\n",
    "    json.dump(report_dataset_info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "01-Extração.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3810jvsc74a57bd0a4783cf7446ebef64c2d24c4fe9f4a266d86f6dd2e7a304b8ae8804c98f80f9f"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "0e11114eded33ad68143fd666caabe644544be984b0693b56435e1b55b430f7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}