{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_KK2usinYme"
   },
   "source": [
    "# URLs para obtenção dos datasets (Obtido dia 07/06/2021)\n",
    "- ### Explicação dos datasets: https://repositoriodatasharingfapesp.uspdigital.usp.br/\n",
    "- ### Dataset do hospital Albert Einstein: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/98 - (2020-06-30)\n",
    "- ### Dataset do hospital Sirio Libanes: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/97 (2020-06-30)\n",
    "- ### Dataset do hospital Beneficencia Portuguesa: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/101 (2021-04-28)\n",
    "- ### Dataset do grupo Fleury: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/99 - (2020-06-30)\n",
    "- ### Dataset do hospital das clinicas da faculdade de medicina da Universidade de São Paulo: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/100 - (2021-02-17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LHakcR8arKVZ"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "current_path = os.path.abspath(os.getcwd())\n",
    "sys.path.append(f\"{current_path}/../libs\")\n",
    "\n",
    "from plot import plot_confusion_matrix, plot_table\n",
    "from dataframe import read_dataset\n",
    "from report import dataset_info_report, model_report, feature_selection_report\n",
    "from preprocess import remove_sparse_rows, remove_sparse_columns, under_sampling, one_hot_encoded\n",
    "from feature_selection import get_k_best, fs_results_filter\n",
    "from cross_validation import get_folds\n",
    "from config import load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Defining Constants and Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"../config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_report = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Auxiliar Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_analysis(df,fs_model_name,columns):\n",
    "    path = f\"{config.ANALYSIS_PATH}\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    concatenated_dataset_df = df[df[\"grupo\"]==\"concatenated-dataset\"]\n",
    "    concatenated_dataset_df = concatenated_dataset_df[columns]\n",
    "    concatenated_dataset_df.reset_index(drop=True, inplace=True)\n",
    "    prof = ProfileReport(concatenated_dataset_df.drop([\"LABEL\",\"grupo\"],axis=1))\n",
    "    prof.to_file(output_file=f\"{path}{fs_model_name}-features-analysis.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Reading Normalized Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data = []\n",
    "for dataset in config.DATASETS:\n",
    "    df = read_dataset(dataset).drop(\"ID_PACIENTE\",axis=1)\n",
    "    df[\"grupo\"] = dataset\n",
    "    complete_data.append(df)\n",
    "raw_df = pd.concat(complete_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Reading Features Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.REPORT_PATH+'features-result.json', 'r') as fp:\n",
    "    features_report = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df = remove_sparse_columns(raw_df)\n",
    "preprocessed_df = remove_sparse_rows(preprocessed_df)\n",
    "data_df = preprocessed_df.drop([\"grupo\"],axis=1)\n",
    "one_hot_encoded_df = one_hot_encoded(data_df)\n",
    "df = one_hot_encoded_df\n",
    "df[\"grupo\"] = preprocessed_df[\"grupo\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Apply models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Decision Tree\" : tree.DecisionTreeClassifier(),\n",
    "    \"Random Forest\" : RandomForestClassifier(random_state=42),\n",
    "    \"KNN\" : KNeighborsClassifier(),\n",
    "    \"Logistic Regression\" : LogisticRegression(max_iter=1000),\n",
    "    \"SVM\" : SVC(probability=True, class_weight='balanced')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarize dataset: 100%|██████████| 48/48 [00:30<00:00,  1.58it/s, Completed]\n",
      "Generate report structure: 100%|██████████| 1/1 [00:11<00:00, 11.26s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 108.15it/s]\n",
      "Summarize dataset: 100%|██████████| 43/43 [00:23<00:00,  1.80it/s, Completed]\n",
      "Generate report structure: 100%|██████████| 1/1 [00:09<00:00,  9.94s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 103.16it/s]\n",
      "Summarize dataset: 100%|██████████| 43/43 [00:24<00:00,  1.79it/s, Completed]\n",
      "Generate report structure: 100%|██████████| 1/1 [00:09<00:00,  9.90s/it]\n",
      "Render HTML: 100%|██████████| 1/1 [00:01<00:00,  1.53s/it]\n",
      "Export report to file: 100%|██████████| 1/1 [00:00<00:00, 114.98it/s]\n"
     ]
    }
   ],
   "source": [
    "for fs_model, fs_results in features_report.items():\n",
    "    if fs_model not in fs_report:\n",
    "        fs_report[fs_model]={}\n",
    "    fs_filtered_results = list(fs_results_filter(fs_results[\"features-result\"],config.N_FEATURES_BEST_THRESHOLD))\n",
    "    # fs_filtered_results = list(fs_results[\"features-result\"].keys())\n",
    "    fs_filtered_results.extend([\"LABEL\",\"grupo\"])\n",
    "    fs_report[fs_model][\"N Features\"] = len(fs_filtered_results)\n",
    "    fs_report[fs_model][\"Features\"] = fs_filtered_results\n",
    "    columns = [x for x in df.columns if x in fs_filtered_results]\n",
    "    get_features_analysis(df,fs_model,columns)\n",
    "    grouped = df.groupby(df.grupo)\n",
    "    dfs = [grouped.get_group(dataset) for dataset in config.DATASETS]\n",
    "\n",
    "    fs_dfs = [df[columns] for df in dfs]\n",
    "    for fold_df,dataset in zip(fs_dfs,config.DATASETS):\n",
    "        for model_name, model in models.items():\n",
    "            if model_name in config.MODELS:\n",
    "                if model_name not in fs_report[fs_model]:\n",
    "                    fs_report[fs_model][model_name]={}\n",
    "                if dataset not in fs_report[fs_model][model_name]:\n",
    "                    fs_report[fs_model][model_name][dataset]={}\n",
    "                train = [df_train for df_train in fs_dfs if not df_train.equals(fold_df)]\n",
    "                train_df = under_sampling(pd.concat(train),False)\n",
    "                test_df = under_sampling(fold_df,False)\n",
    "\n",
    "                X_train = train_df.drop([\"LABEL\",\"grupo\"],axis=1)\n",
    "                y_train = train_df[\"LABEL\"]\n",
    "                X_test = test_df.drop([\"LABEL\",\"grupo\"],axis=1)\n",
    "                y_test = test_df[\"LABEL\"]\n",
    "            \n",
    "                model.fit(X_train, y_train.values.ravel())\n",
    "                y_predicted=model.predict(X_test)\n",
    "                \n",
    "                fs_report[fs_model][model_name][dataset]=model_report(y_test,y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Save Feature Selection Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{config.REPORT_PATH}\"\n",
    "\n",
    "with open(f\"{path}final-results.json\", 'w') as f:\n",
    "    json.dump(fs_report, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "01-Extração.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3810jvsc74a57bd0a4783cf7446ebef64c2d24c4fe9f4a266d86f6dd2e7a304b8ae8804c98f80f9f"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "0e11114eded33ad68143fd666caabe644544be984b0693b56435e1b55b430f7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}