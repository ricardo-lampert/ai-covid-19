{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_KK2usinYme"
   },
   "source": [
    "### URLs para obtenção dos datasets (Obtido dia 07/06/2021)\n",
    "- Explicação dos datasets: https://repositoriodatasharingfapesp.uspdigital.usp.br/\n",
    "- Dataset do hospital Albert Einstein: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/98 - (2020-06-30)\n",
    "- Dataset do hospital Sirio Libanes: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/97 (2020-06-30)\n",
    "- Dataset do hospital Beneficencia Portuguesa: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/101 (2021-04-28)\n",
    "- Dataset do grupo Fleury: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/99 - (2020-06-30)\n",
    "- Dataset do hospital das clinicas da faculdade de medicina da Universidade de São Paulo: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/100 - (2021-02-17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LHakcR8arKVZ"
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "current_path = os.path.abspath(os.getcwd())\n",
    "sys.path.append(f\"{current_path}/../libs\")\n",
    "\n",
    "from dataframe import read_dataset, split_train_test\n",
    "from report import dataset_info_report, feature_selection_report\n",
    "from preprocess import remove_sparse_rows, remove_sparse_columns, under_sampling, one_hot_encoded\n",
    "from feature_selection import get_k_best, get_extra_trees_classifier, get_rfe\n",
    "from cross_validation import get_folds\n",
    "from config import load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Configs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read configd snd define globals\n",
    "config = load_config(\"../config.yaml\")\n",
    "\n",
    "report_feature_selection = {}\n",
    "report_dataset_info = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read normalized datasets\n",
    "df_list = []\n",
    "for dataset in config.DATASETS:\n",
    "    df = read_dataset(dataset).drop(\"ID_PACIENTE\",axis=1)\n",
    "    df_list.append(df)\n",
    "    \n",
    "for df,dataset in zip(df_list,config.DATASETS):\n",
    "    if \"raw dataset\" not in report_dataset_info:\n",
    "        report_dataset_info[\"raw dataset\"]={}\n",
    "    report_dataset_info[\"raw dataset\"][dataset]=dataset_info = {\n",
    "        \"shape\": {\"instances\": df.shape[0], \"features\": df.shape[1]},\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Preprocess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocess to datasets\n",
    "preprocessed_df_list = []\n",
    "report_dataset_info[\"preprocessed_dataset\"]={}\n",
    "for df,dataset in zip(df_list,config.DATASETS):\n",
    "    preprocessed_df = remove_sparse_columns(df)\n",
    "    preprocessed_df = remove_sparse_rows(preprocessed_df)\n",
    "    report_dataset_info[\"preprocessed_dataset\"][dataset]=dataset_info = {\n",
    "        \"shape\": {\"instances\": preprocessed_df.shape[0], \"features\": preprocessed_df.shape[1]},}\n",
    "    one_hot_encoded_df = one_hot_encoded(preprocessed_df)\n",
    "    preprocessed_df_list.append(one_hot_encoded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc33109cdaf4825b68f0e3c689df945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Analyzing best features for each datasets with 10 folds cross validation:   0%|          | 0/6 [00:00<?, ?it/s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3e637292ef4d06b4c4f0199fa255f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- - Applying feature selection models to each fold:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44396b146ed24820a4e84dfd9211bf24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- - - - Applying feature selection models:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ee6269365348b4a4b2479383bfc1e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- - - - Applying feature selection models:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply feature selection in a cross validation\n",
    "for fs_model in config.FS_MODELS:\n",
    "    report_feature_selection[fs_model]={}\n",
    "for df,dataset in tqdm(zip(preprocessed_df_list,config.DATASETS),total=len(config.DATASETS),desc=\"Analyzing best features for each datasets with 10 folds cross validation\"):\n",
    "    for fs_model in config.FS_MODELS:\n",
    "        report_feature_selection[fs_model][dataset]={}\n",
    "    if dataset == \"concatenated-dataset\":\n",
    "        prof = ProfileReport(df.drop([\"LABEL\",\"grupo\"],axis=1))\n",
    "        prof.to_file(output_file=f\"{config.ANALYSIS_PATH}-features-analysis.html\")\n",
    "    folds = get_folds(df,config.N_FOLDS)\n",
    "    best_features = []\n",
    "    for index,fold in tqdm(enumerate(folds),total=len(folds),desc=\"- - Applying feature selection models to each fold\"):\n",
    "    # for index,fold in enumerate(folds):\n",
    "        train_df,test_df=fold\n",
    "        X_train, y_train, X_test, y_test = split_train_test(train_df,test_df)\n",
    "        for fs_model in tqdm(config.FS_MODELS,total=len(config.FS_MODELS),desc=\"- - - - Applying feature selection models\"):\n",
    "        # for fs_model in config.FS_MODELS:\n",
    "            k_best = get_k_best(df,X_train,y_train.values.ravel(), fs_model, None)\n",
    "            report_feature_selection[fs_model][dataset][f\"fold {index}\"]=k_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "path = config.REPORT_PATH\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "with open(f\"{path}best-features.json\", 'w') as f:\n",
    "    json.dump(report_feature_selection, f)\n",
    "\n",
    "with open(f\"{path}info-dataset.json\", 'w') as f:\n",
    "    json.dump(report_dataset_info, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "01-Extração.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "9377aa7791427010e3814f602708cbf34f157433a2a5e27524401e81af2d8975"
  },
  "kernelspec": {
   "display_name": "tcc-02",
   "language": "python",
   "name": "tcc-02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "0e11114eded33ad68143fd666caabe644544be984b0693b56435e1b55b430f7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
