{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_KK2usinYme"
   },
   "source": [
    "# URLs para obtenção dos datasets (Obtido dia 07/06/2021)\n",
    "- ### Explicação dos datasets: https://repositoriodatasharingfapesp.uspdigital.usp.br/\n",
    "- ### Dataset do hospital Albert Einstein: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/98 - (2020-06-30)\n",
    "- ### Dataset do hospital Sirio Libanes: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/97 (2020-06-30)\n",
    "- ### Dataset do hospital Beneficencia Portuguesa: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/101 (2021-04-28)\n",
    "- ### Dataset do grupo Fleury: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/99 - (2020-06-30)\n",
    "- ### Dataset do hospital das clinicas da faculdade de medicina da Universidade de São Paulo: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/100 - (2021-02-17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "LHakcR8arKVZ"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from operator import itemgetter\n",
    "import os\n",
    "import sys\n",
    "\n",
    "current_path = os.path.abspath(os.getcwd())\n",
    "sys.path.append(f\"{current_path}/../libs\")\n",
    "\n",
    "from plot import plot_confusion_matrix, plot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Defining Constants and Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETE_DATASET_REPORT_PATH = \"../reports/complete-dataset/\"\n",
    "EACH_DATASET_REPORT_PATH = \"../reports/each-dataset/\"\n",
    "INTERIM_REPORT_PATH = \"../reports/interim/\"\n",
    "PLOTS_FEATURE_SELECTION_PATH = \"../plots/feature_selection/\"\n",
    "REPORT_PATH = \"../reports/\"\n",
    "DATASETS = [\n",
    "    \"albert-einstein\",\n",
    "    \"beneficencia-portuguesa\",\n",
    "    \"hospital-de-clinicas\",\n",
    "    \"sirio-libanes\",\n",
    "    \"grupo-fleury\"\n",
    "    ]\n",
    "\n",
    "FEATURE_SELECTION_MODELS = [\n",
    "    \"select-k-best\"\n",
    "]\n",
    "N_FEATURES = 15\n",
    "\n",
    "report_interim = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Auxiliar Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Reading Complete Dataset Feature Selection Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(INTERIM_REPORT_PATH+'feature-selection-results.json', 'r') as fp:\n",
    "    feature_selection_report = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_names = [\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"KNN\" ,\n",
    "    # \"Logistic Regression\",\n",
    "    # \"SVM\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row(ml_results):\n",
    "    n_hospitals = len(ml_results)\n",
    "    accuracy = 0\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f1_score = 0\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    for hospital, metrics in ml_results.items():\n",
    "        accuracy += float(metrics[\"accuracy\"])\n",
    "        precision += float(metrics[\"precision\"])\n",
    "        recall += float(metrics[\"recall\"])\n",
    "        f1_score += float(metrics[\"f1-score\"])\n",
    "        tp += float(metrics[\"confusion matrix\"][\"tp\"])\n",
    "        tn += float(metrics[\"confusion matrix\"][\"tn\"])\n",
    "    \n",
    "    avg_acc = round(accuracy/n_hospitals,3)\n",
    "    avg_prec = round(precision/n_hospitals,3)\n",
    "    avg_rec =round(recall/n_hospitals,3)\n",
    "    avg_f1 =round(f1_score/n_hospitals,3)\n",
    "\n",
    "    acc=0\n",
    "    prec=0\n",
    "    rec = 0\n",
    "    f1 = 0\n",
    "\n",
    "    for hospital, metrics in ml_results.items():\n",
    "        acc += pow(abs(float(metrics[\"accuracy\"])-avg_acc),2)\n",
    "        prec += pow(abs(float(metrics[\"precision\"])-avg_prec),2)\n",
    "        rec += pow(abs(float(metrics[\"recall\"])-avg_rec),2)\n",
    "        f1 += pow(abs(float(metrics[\"f1-score\"])-avg_f1),2)\n",
    "\n",
    "    std_var_acc = round(pow((acc/(len(ml_results))),1/2),3)\n",
    "    std_var_prec = round(pow((prec/(len(ml_results))),1/2),3)\n",
    "    std_var_rec = round(pow((rec/(len(ml_results))),1/2),3)\n",
    "    std_var_f1 = round(pow((f1/(len(ml_results))),1/2),3)\n",
    "    \n",
    "    tp = round(tp/n_hospitals,3)\n",
    "    tn = round(tn/n_hospitals,3)\n",
    "    fp = round(1 - tp/n_hospitals,3)\n",
    "    fn = round(1 - tn/n_hospitals,3)\n",
    "\n",
    "    return [\n",
    "        str(f\"{avg_acc} +- {std_var_acc}\"),\n",
    "        str(f\"{avg_prec} +- {std_var_prec}\"),\n",
    "        str(f\"{avg_rec} +- {std_var_rec}\"),\n",
    "        str(f\"{avg_f1} +- {std_var_f1}\"),\n",
    "        tp,\n",
    "        tn,\n",
    "        fp,\n",
    "        fn,\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.86 +- 0.0', '0.71 +- 0.0', '0.884 +- 0.005', '0.79 +- 0.0', 0.884, 0.85, 0.823, 0.83], ['0.87 +- 0.0', '0.73 +- 0.0', '0.9 +- 0.0', '0.806 +- 0.005', 0.9, 0.86, 0.82, 0.828], ['0.772 +- 0.007', '0.59 +- 0.014', '0.782 +- 0.007', '0.67 +- 0.006', 0.782, 0.77, 0.844, 0.846]]\n"
     ]
    }
   ],
   "source": [
    "feature_selection_results = {}\n",
    "for model,results in feature_selection_report.items():\n",
    "    data = []\n",
    "    columns = [\n",
    "        \"accuracy\",\"precision\",\"recall\",\"f1-score\",\n",
    "        \"tp\",\"tn\",\"fp\",\"fn\"]\n",
    "    feature_selection_results[model] = {}\n",
    "    for ml_model, ml_results in results.items(): \n",
    "        \n",
    "\n",
    "        if ml_model in models_names:\n",
    "            data.append(get_row(ml_results))\n",
    "\n",
    "\n",
    "\n",
    "    path = f\"{PLOTS_FEATURE_SELECTION_PATH}result/\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    print(data)\n",
    "    plot_table(\n",
    "        data,\n",
    "        columns=columns, \n",
    "        rows=models_names,\n",
    "        path=path+\"metrics\",\n",
    "        title = (model+\" Results\"))\n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "01-Extração.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3810jvsc74a57bd0a4783cf7446ebef64c2d24c4fe9f4a266d86f6dd2e7a304b8ae8804c98f80f9f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "0e11114eded33ad68143fd666caabe644544be984b0693b56435e1b55b430f7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}