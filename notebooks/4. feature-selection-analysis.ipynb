{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_KK2usinYme"
   },
   "source": [
    "# URLs para obtenção dos datasets (Obtido dia 07/06/2021)\n",
    "- ### Explicação dos datasets: https://repositoriodatasharingfapesp.uspdigital.usp.br/\n",
    "- ### Dataset do hospital Albert Einstein: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/98 - (2020-06-30)\n",
    "- ### Dataset do hospital Sirio Libanes: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/97 (2020-06-30)\n",
    "- ### Dataset do hospital Beneficencia Portuguesa: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/101 (2021-04-28)\n",
    "- ### Dataset do grupo Fleury: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/99 - (2020-06-30)\n",
    "- ### Dataset do hospital das clinicas da faculdade de medicina da Universidade de São Paulo: https://repositoriodatasharingfapesp.uspdigital.usp.br/handle/item/100 - (2021-02-17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LHakcR8arKVZ"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "current_path = os.path.abspath(os.getcwd())\n",
    "sys.path.append(f\"{current_path}/../libs\")\n",
    "\n",
    "from plot import plot_confusion_matrix, plot_table\n",
    "from dataframe import read_dataset\n",
    "from report import dataset_info_report, model_report, feature_selection_report\n",
    "from preprocess import remove_sparse_rows, remove_sparse_columns, under_sampling, one_hot_encoded\n",
    "from feature_selection import get_k_best, fs_results_filter\n",
    "from cross_validation import get_folds\n",
    "from config import load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Defining Constants and Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"../config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_report = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Reading Normalized Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data = []\n",
    "for dataset in config.DATASETS:\n",
    "    df = read_dataset(dataset).drop(\"ID_PACIENTE\",axis=1)\n",
    "    df[\"grupo\"] = dataset\n",
    "    complete_data.append(df)\n",
    "raw_df = pd.concat(complete_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Reading Features Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config.REPORT_PATH+'features-result.json', 'r') as fp:\n",
    "    features_report = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df = remove_sparse_columns(raw_df)\n",
    "preprocessed_df = remove_sparse_rows(preprocessed_df)\n",
    "data_df = preprocessed_df.drop([\"grupo\"],axis=1)\n",
    "one_hot_encoded_df = one_hot_encoded(data_df)\n",
    "df = one_hot_encoded_df\n",
    "df[\"grupo\"] = preprocessed_df[\"grupo\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Analyse Best threshold for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Decision Tree\" : tree.DecisionTreeClassifier(),\n",
    "    \"Random Forest\" : RandomForestClassifier(random_state=42),\n",
    "    \"KNN\" : KNeighborsClassifier(),\n",
    "    \"Logistic Regression\" : LogisticRegression(max_iter=1000),\n",
    "    \"SVM\" : SVC(probability=True, class_weight='balanced')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_analysis = {}\n",
    "for fs_model, fs_results in features_report.items():\n",
    "    if fs_model not in fs_analysis:\n",
    "        fs_analysis[fs_model]={}\n",
    "    for n_features in range(config.N_FEATURES_THRESHOLD): \n",
    "        fs_filtered_results = list(fs_results_filter(fs_results[\"features-result\"],n_features+1))\n",
    "        fs_filtered_results.extend([\"LABEL\",\"grupo\"])\n",
    "        columns = [x for x in df.columns if x in fs_filtered_results]\n",
    "        grouped = df.groupby(df.grupo)\n",
    "        dfs = [grouped.get_group(dataset) for dataset in config.DATASETS]\n",
    "        fs_dfs = [df[columns] for df in dfs]\n",
    "        for fold_df,dataset in zip(fs_dfs,config.DATASETS):\n",
    "            for model_name, model in models.items():\n",
    "                if model_name in config.MODELS:\n",
    "                    threshold = f\"{n_features+1} features\"\n",
    "                    if model_name not in fs_analysis[fs_model]:\n",
    "                        fs_analysis[fs_model][model_name]={}\n",
    "                    if dataset not in fs_analysis[fs_model][model_name]:\n",
    "                        fs_analysis[fs_model][model_name][dataset]={}\n",
    "                    if threshold not in fs_analysis[fs_model][model_name][dataset]:\n",
    "                        fs_analysis[fs_model][model_name][dataset][threshold]={}\n",
    "                    \n",
    "                    train = [df_train for df_train in fs_dfs if not df_train.equals(fold_df)]\n",
    "                    train_df = under_sampling(pd.concat(train),False)\n",
    "                    test_df = under_sampling(fold_df,False)\n",
    "\n",
    "                    X_train = train_df.drop([\"LABEL\",\"grupo\"],axis=1)\n",
    "                    y_train = train_df[\"LABEL\"]\n",
    "                    X_test = test_df.drop([\"LABEL\",\"grupo\"],axis=1)\n",
    "                    y_test = test_df[\"LABEL\"]\n",
    "                \n",
    "                    model.fit(X_train, y_train.values.ravel())\n",
    "                    y_predicted=model.predict(X_test)\n",
    "                    \n",
    "                    fs_analysis[fs_model][model_name][dataset][threshold]=model_report(y_test,y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Save Feature Selection Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{config.REPORT_PATH}\"\n",
    "\n",
    "with open(f\"{path}feature-analysis.json\", 'w') as f:\n",
    "    json.dump(fs_analysis, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "01-Extração.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3810jvsc74a57bd0a4783cf7446ebef64c2d24c4fe9f4a266d86f6dd2e7a304b8ae8804c98f80f9f"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "0e11114eded33ad68143fd666caabe644544be984b0693b56435e1b55b430f7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}